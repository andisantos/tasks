{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  OCR (Optical Character Recognition) - Experimento\n",
    "## Utilização das bibliotecas [opencv](https://opencv.org/) e  [Tesseract OCR](https://tesseract-ocr.github.io/) para o reconhecimento de texto em imagens e da biblioteca [JiWER](https://github.com/jitsi/jiwer) para cálculo de mérticas de perfomance\n",
    "\n",
    "*   Mais detlalhes sobre  o funcionamento dos algorítimos e das línguas nos quais o mesmo podem são utilizados são encontrados na [Tesseract documentation](https://tesseract-ocr.github.io/tessdoc/Data-Files)\n",
    "\n",
    "*   Caso seja passado um arquivo .xlsx com as strings de target pode visualizar a perfonrmance do algorítimo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "O parâmetro `dataset` identifica os conjuntos de dados. Você pode importar arquivos de dataset com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/OCR_dataset.zip\" #@param {type:\"string\"}\n",
    "target = \"target_OCR\" #@param {type:\"string\", label:\"Atributo alvo\", description:\"Seu modelo tentará prever os valores do alvo.\"}\n",
    "filter_type = \"incluir\" #@param [\"incluir\"] {type:\"string\",label:\"Modo de seleção das features\",description:\"Neste caso está travdo em incluir porque o OCR precisa apenas do caminho da imagem\"}\n",
    "model_features = \"input_image\" #@param {type:\"string\",description:\"Seu modelo será feito considerando apenas as features selecionadas. Caso nada seja especificado, todas as features serão utilizadas\"}\n",
    "\n",
    "#Hyperparams\n",
    "bbox_conf = 60 #@param {type:\"number\",label:\"Confiabilidade do bbox\", description:\"O quanto de confiabilidade o algorítmo deve possuir sobre o bbox para que o mesmo apareça.\"}\n",
    "\n",
    "#Pytesseact Params\n",
    "segmentation_mode = \"Assume a single uniform block of text.\"  #@param [\"Orientation and script detection (OSD) only.\",\"Automatic page segmentation with OSD.\",\"Automatic page segmentation, but no OSD, or OCR.\",\"Fully automatic page segmentation, but no OSD. (Default)\",\"Assume a single column of text of variable sizes.\",\"Assume a single uniform block of vertically aligned text.\",\"Assume a single uniform block of text.\",\"Treat the image as a single text line.\",\"Treat the image as a single word.\",\"Treat the image as a single word in a circle.\",\"Treat the image as a single character.\",\"Sparse text. Find as much text as possible in no particular order.\",\"Sparse text with OSD\",\"Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.\"] {type:\"string\",label:\"Modeo de segmentação do PyTesseract\",description:\"Para mais informações acesse a documentação linkada no inicio do notebook\"}\n",
    "ocr_engine = \"Neural nets LSTM engine only.\" #@param [\"Legacy engine only.\",\"Neural nets LSTM engine only.\",\"Legacy + LSTM engines.\",\"Default, based on what is available.\"] {type:\"string\",label:\"OCR engine do Pytesseract\",description:\"Para mais informações acesse a documentação linkada no inicio do notebook\"}\n",
    "language = \"por\" #@param [\"por\",\"eng\"] {type:\"string\",label:\"Idioma pré teinado\",description:\"Para mais informações acesse a documentação linkada no inicio do notebook\"}\n",
    "\n",
    "#Return formart\n",
    "bbox_return = \"image\" #@param [\"np_array\",\"image\"] {type:\"string\",label:\"Forma de retorno dos bboxes\",description:\"Escolher se bboxes serão retornados na imagem ou como um numpy array\"}\n",
    "image_return_format = \".jpg\" #@param [\"N/A\",\".jpg\",\".png\"] {type:\"string\",label:\"Formato de retorno da imagem caso bbox_return = image\",description:\"Escolher formato de retorno da imagem, N/A se retornar numpy array\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao conjunto de dados\n",
    "\n",
    "O conjunto de dados utilizado nesta etapa será o mesmo carregado através da plataforma.<br>\n",
    "O tipo da variável retornada depende do arquivo de origem:\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) para CSV e compressed CSV: .csv .csv.zip .csv.gz .csv.bz2 .csv.xz\n",
    "- [Binary IO stream](https://docs.python.org/3/library/io.html#binary-i-o) para outros tipos de arquivo: .jpg .wav .zip .h5 .parquet etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/data/OCR_dataset.zip\n",
      "  inflating: /tmp/data/OCR_dataset/motiv3.jpg  \n",
      "  inflating: /tmp/data/OCR_dataset/motiv2.jpg  \n",
      "  inflating: /tmp/data/OCR_dataset/motiv1.png  \n",
      "  inflating: /tmp/data/OCR_dataset/OCR_dataset.xlsx  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folder = os.path.join(\"/tmp/data\",\"OCR_dataset\")\n",
    "\n",
    "!mkdir -p {folder}\n",
    "!unzip -o {dataset} -d {folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tmp/data/OCR_dataset/OCR_dataset.xlsx',\n",
       " ['/tmp/data/OCR_dataset/motiv2.jpg',\n",
       "  '/tmp/data/OCR_dataset/motiv1.png',\n",
       "  '/tmp/data/OCR_dataset/motiv3.jpg'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = os.path.join(\"/tmp/data\",\"OCR_dataset\")\n",
    "dataset_path = \"\"\n",
    "image_paths = []\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        dataset_path = os.path.join(folder, file)\n",
    "    else:\n",
    "        image_paths.append(os.path.join(folder, file))\n",
    "dataset_path,image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_image</th>\n",
       "      <th>target_OCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tmp/data/OCR_dataset/motiv1.png</td>\n",
       "      <td>Se não puder fazer tudo, faça tudo o que puder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tmp/data/OCR_dataset/motiv2.jpg</td>\n",
       "      <td>Comece acreditando que é possível</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tmp/data/OCR_dataset/motiv3.jpg</td>\n",
       "      <td>Ainda que doa, valerá a pena. Esquece o medo v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        input_image  \\\n",
       "0  /tmp/data/OCR_dataset/motiv1.png   \n",
       "1  /tmp/data/OCR_dataset/motiv2.jpg   \n",
       "2  /tmp/data/OCR_dataset/motiv3.jpg   \n",
       "\n",
       "                                          target_OCR  \n",
       "0     Se não puder fazer tudo, faça tudo o que puder  \n",
       "1                  Comece acreditando que é possível  \n",
       "2  Ainda que doa, valerá a pena. Esquece o medo v...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"input_image\"] = folder + \"/\" + df[\"input_image\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso aos metadados do conjunto de dados\n",
    "\n",
    "Utiliza a função `stat_dataset` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para carregar metadados.<br>\n",
    "Por exemplo, arquivos CSV possuem `metadata['featuretypes']` para cada coluna no conjunto de dados (ex: categorical, numerical, or datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['input_image'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de linhas com valores faltantes no atributo alvo\n",
    "Caso haja linhas em que o atributo alvo contenha valores faltantes, é feita a remoção dos casos faltantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Se não puder fazer tudo, faça tudo o que puder',\n",
       "       'Comece acreditando que é possível',\n",
       "       'Ainda que doa, valerá a pena. Esquece o medo voa. Só voa.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df.dropna(subset=[target], inplace=True)\n",
    "df.dropna(subset=[columns[0]], inplace=True)\n",
    "y = df[target].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtragem das features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['/tmp/data/OCR_dataset/motiv1.png'],\n",
       "       ['/tmp/data/OCR_dataset/motiv2.jpg'],\n",
       "       ['/tmp/data/OCR_dataset/motiv3.jpg']], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if filter_type == 'incluir':\n",
    "    if len(model_features) >= 1:\n",
    "        columns_index = (np.where(np.isin(columns,model_features)))[0]\n",
    "        columns_index.sort()\n",
    "        columns_to_filter = columns[columns_index]\n",
    "        #featuretypes = featuretypes[columns_index]\n",
    "    else:\n",
    "        columns_to_filter = columns\n",
    "else:\n",
    "    if len(model_features) >= 1:\n",
    "        columns_index = (np.where(np.isin(columns,model_features)))[0]\n",
    "        columns_index.sort()\n",
    "        columns_to_filter = np.delete(columns,columns_index)\n",
    "        #featuretypes = np.delete(featuretypes,columns_index)\n",
    "    else:\n",
    "        columns_to_filter = columns\n",
    "\n",
    "# keep the features selected\n",
    "df = df[columns_to_filter]\n",
    "X = df.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chamada da Classe de OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'bbox_conf':bbox_conf}\n",
    "model_parameters = {'ocr_engine':ocr_engine,'segmentation_mode':segmentation_mode,'language':language}\n",
    "return_formats = {'bbox_return':bbox_return,'image_return_format':image_return_format}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-26 11:40:02--  https://raw.githubusercontent.com/platiagro/tasks/main/tasks/cv-ocr/ocr.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.92.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.92.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7172 (7.0K) [text/plain]\n",
      "Saving to: ‘ocr.py’\n",
      "\n",
      "ocr.py              100%[===================>]   7.00K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-10-26 11:40:03 (26.8 MB/s) - ‘ocr.py’ saved [7172/7172]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/platiagro/tasks/main/tasks/cv-ocr/ocr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_ocr_text</th>\n",
       "      <th>predicted_ocr_text</th>\n",
       "      <th>BBOXES_COORDS(X, Y, W, H)</th>\n",
       "      <th>Match Error Rate (MER)</th>\n",
       "      <th>Word Error Rate (WER)</th>\n",
       "      <th>Word Information Lost (WIL)</th>\n",
       "      <th>Word Information Preserved (WIP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tmp/data/OCR_dataset/motiv1.png</td>\n",
       "      <td>Se não puder fazer tudo, faça tudo o que puder</td>\n",
       "      <td>Se não\\npuder fazer\\ntudo,\\n\\nfaça tudo\\nque p...</td>\n",
       "      <td>[(126, 517, 147, 102), (304, 517, 238, 102), (...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tmp/data/OCR_dataset/motiv2.jpg</td>\n",
       "      <td>Comece acreditando que é possível</td>\n",
       "      <td>COMECE\\nACREDITANDO\\nOJja\\nPOSSÍVEL (9\\nYV\\n</td>\n",
       "      <td>[(347, 680, 387, 75), (207, 826, 663, 75), (31...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tmp/data/OCR_dataset/motiv3.jpg</td>\n",
       "      <td>Ainda que doa, valerá a pena. Esquece o medo v...</td>\n",
       "      <td>Ainda que doa, valerá a\\npena. Esquece o medo ...</td>\n",
       "      <td>[(138, 215, 71, 16), (225, 219, 41, 17), (282,...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        source_text  \\\n",
       "0  /tmp/data/OCR_dataset/motiv1.png   \n",
       "1  /tmp/data/OCR_dataset/motiv2.jpg   \n",
       "2  /tmp/data/OCR_dataset/motiv3.jpg   \n",
       "\n",
       "                                     target_ocr_text  \\\n",
       "0     Se não puder fazer tudo, faça tudo o que puder   \n",
       "1                  Comece acreditando que é possível   \n",
       "2  Ainda que doa, valerá a pena. Esquece o medo v...   \n",
       "\n",
       "                                  predicted_ocr_text  \\\n",
       "0  Se não\\npuder fazer\\ntudo,\\n\\nfaça tudo\\nque p...   \n",
       "1      COMECE\\nACREDITANDO\\nOJja\\nPOSSÍVEL (9\\nYV\\n\n",
       "   \n",
       "2  Ainda que doa, valerá a\\npena. Esquece o medo ...   \n",
       "\n",
       "                           BBOXES_COORDS(X, Y, W, H)  Match Error Rate (MER)  \\\n",
       "0  [(126, 517, 147, 102), (304, 517, 238, 102), (...                0.300000   \n",
       "1  [(347, 680, 387, 75), (207, 826, 663, 75), (31...                0.714286   \n",
       "2  [(138, 215, 71, 16), (225, 219, 41, 17), (282,...                0.142857   \n",
       "\n",
       "    Word Error Rate (WER)  Word Information Lost (WIL)  \\\n",
       "0                0.300000                     0.510000   \n",
       "1                1.000000                     0.885714   \n",
       "2                0.166667                     0.142857   \n",
       "\n",
       "   Word Information Preserved (WIP)  \n",
       "0                          0.490000  \n",
       "1                          0.114286  \n",
       "2                          0.857143  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocr import Class_Pytesseract_OCR\n",
    "model = Class_Pytesseract_OCR(hyperparams,model_parameters)\n",
    "model.get_result_dataframe(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva métricas\n",
    "\n",
    "Utiliza a função `save_metrics` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar as métricas:`MER`, `WER`, `WIL`, `WIP` <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(MER=model.avg_mer, WER=model.avg_wer, WIL=model.avg_wil, WIP=model.avg_wip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva modelo e outros resultados do treinamento\n",
    "\n",
    "Escreve todos artefatos na pasta `/tmp/data/`. A plataforma guarda os artefatos desta pasta para usos futuros como implantação e comparação de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/data/ocr.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"hyperparams\": hyperparams,\n",
    "    \"model_parameters\": model_parameters,\n",
    "    \"return_formats\":return_formats\n",
    "}\n",
    "\n",
    "dump(artifacts, \"/tmp/data/ocr.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "c11318b7-3905-4397-87bd-4b019b628a40",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "operator_id": "ddc6e842-4036-473a-951d-b30839179d78",
  "task_id": "f8e20efb-def0-4e1c-9927-9bf14214570a"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
